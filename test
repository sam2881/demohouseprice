import json
import re
from typing import Union, List, Dict, Any
import logging

logging.basicConfig(level=logging.DEBUG)

def parse_and_generate_rules(data: dict, rules: list, prefix: str = "") -> None:
    """
    Parses nested JSON data and generates validation rules.

    Args:
        data: The JSON data to be parsed (dict).
        rules: A list to store the generated rules.
        prefix: A string prefix for nested fields (default empty string).
    """
    for key, value in data.items():
        # Use only the current field name for rule generation, ignoring prefix
        field_name = key
        logging.debug(f"Processing field: {field_name}")
        
        if isinstance(value, dict):
            # Recurse for nested dictionaries
            parse_and_generate_rules(value, rules, field_name + ".")
        elif isinstance(value, list):
            # Array handling
            if value:
                if isinstance(value[0], dict):
                    # Array of dictionaries
                    parse_and_generate_rules(value[0], rules, field_name + ".")
                else:
                    # Array of simple types
                    rule_id = len(rules) + 1
                    rule = generate_rule(field_name, value[0], rule_id, is_array=True)
                    rules.append(rule)
            else:
                # Handle empty array as non-null
                rule_id = len(rules) + 1
                rule = generate_rule(field_name, None, rule_id, is_array=True)
                rules.append(rule)
        else:
            # Generate rule for scalar values
            rule_id = len(rules) + 1
            rule = generate_rule(field_name, value, rule_id)
            rules.append(rule)

def generate_rule(column_name: str, value: Union[int, float, str, None], rule_id: int, is_array: bool = False) -> dict:
    """
    Generates a validation rule based on the data type or pattern.

    Args:
        column_name: The name of the column in the database table.
        value: The value from the JSON data.
        rule_id: A unique identifier for the rule.
        is_array: Flag indicating if the rule applies to an array (default False).

    Returns:
        A dictionary containing the generated validation rule.
    """
    rule = {
        "rule_id": str(rule_id),
        "display_rule": "Auto-generated validation rule"
    }

    type_map = {
        int: r"^\d+$",
        float: r"^\d+(\.\d+)?$",
        str: None
    }

    # Determine pattern based on type or value
    pattern = type_map.get(type(value))
    if isinstance(value, str) and pattern is None:
        # Additional pattern matching for dates and emails
        if re.match(r"^(19|20)\d{2}-(0[1-9]|1[0-2])-(0[1-9]|[12]\d|3[01])$", value):
            pattern = r"^(19|20)\d{2}-(0[1-9]|1[0-2])-(0[1-9]|[12]\d|3[01])$"
            rule["display_rule"] = "Must be in valid YYYY-MM-DD format."
        elif re.match(r"^[\w\.-]+@[\w\.-]+\.\w+$", value):
            pattern = r"^[\w\.-]+@[\w\.-]+\.\w+$"
            rule["display_rule"] = "Must be a valid email format."
        else:
            # General alphanumeric pattern
            pattern = r"^[\w\s\-,.]+$"
            rule["display_rule"] = "Must be alphanumeric with spaces and basic punctuation."

    # Construct SQL rule based on pattern and array flag
    if pattern:
        sql_rule = (
            f"CASE WHEN rlike({column_name}, '{pattern}') OR {column_name} IS NULL THEN 0 ELSE 1 END"
            if not is_array else f"CASE WHEN array_all({column_name}, '{pattern}') OR {column_name} IS NULL THEN 0 ELSE 1 END"
        )
    else:
        sql_rule = f"CASE WHEN {column_name} IS NOT NULL THEN 0 ELSE 1 END"
        rule["display_rule"] = rule.get("display_rule", "Must be non-null.")

    rule["sql_rule"] = sql_rule
    logging.debug(f"Generated rule: {rule}")
    return rule

def process_json_file(input_filepath: str, output_filepath: str) -> None:
    """
    Loads JSON data, generates rules, and saves them to a file.

    Args:
        input_filepath: Path to the input JSON file.
        output_filepath: Path to the output JSON file for rules.
    """
    try:
        with open(input_filepath, "r") as file:
            input_data = json.load(file)
    except FileNotFoundError:
        logging.error(f"Input file '{input_filepath}' not found.")
        return
    except json.JSONDecodeError:
        logging.error(f"Failed to decode JSON from '{input_filepath}'. Please check the file's contents.")
        return

    rules = []
    parse_and_generate_rules(input_data, rules)

    expectation_suite = {
        "expectation_suite_name": "dynamic_expectation_suite",
        "expectations": rules
    }

    with open(output_filepath, "w") as file:
        json.dump(expectation_suite, file, indent=4)

    logging.info(f"Rules generated and saved to '{output_filepath}'")

# Example usage
input_filepath = "input.json"  # Path to your input JSON file
output_filepath = "generated_rules.json"  # Path to the output rules JSON file

process_json_file(input_filepath, output_filepath)
